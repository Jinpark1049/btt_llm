import streamlit as st
import sys, os
import time
import pandas as pd
from langchain_community.vectorstores import FAISS


sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from btt_parser import *

parser = Biollm(model = 'gemma2:27b')  # Assuming Biollm is a parser class you've defined


# Ensure session state keys exist
if "pdf_path" not in st.session_state:
    st.session_state.pdf_path = None

if "retriever" not in st.session_state:
    st.session_state.retriever = None

if "documents" not in st.session_state:
    st.session_state.documents = None

if "df_result" not in st.session_state:
    st.session_state.df_result = None

if "run_chat_assistant" not in st.session_state:
    st.session_state.run_chat_assistant = False

if "run_llm_parser" not in st.session_state:
    st.session_state.run_llm_parser = False

# Sidebar UI
with st.sidebar:
    st.title('ğŸ“ BTT Report Extractor')    
    # Display uploaded file info
    if st.session_state.pdf_path is not None:
        pdf_path = st.session_state.pdf_path
        st.sidebar.write(f"ğŸ“„ **{os.path.basename(pdf_path)}** is ready.")
    else:
        st.sidebar.write("âš ï¸ No PDF file uploaded.")

    if st.button("ğŸš€ Run LLM Parser"):
        if st.session_state.pdf_path is not None and st.session_state.run_llm_parser == False:
            
            with st.spinner("ğŸ”„ Running LLM Parser... Please wait..."):
                parser.run(st.session_state.pdf_path)  # Run the parser
                new_df = pd.DataFrame([parser.parsed_data])  # ìƒˆ ë°ì´í„° í”„ë ˆì„ ìƒì„±

                # ê¸°ì¡´ final_dfê°€ ì¡´ì¬í•˜ê³ , Noneì´ ì•„ë‹ˆë©° ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€
                st.session_state.run_llm_parser = True
                
                if st.session_state['new_file_uploaded']:
                    st.session_state.df_result = pd.concat([st.session_state.df_result, new_df], ignore_index=True)
                else:
                    st.session_state.df_result = new_df

                parser.refresh()  # Reset parser state
            st.sidebar.success("âœ… LLM Parser finished!")
        elif st.session_state.run_llm_parser == True:
            st.warning("âš ï¸ Please upload a new PDF file first.")
        
        else:
            st.sidebar.warning("âš ï¸ Please upload a PDF first.")

    # chatbot
    if st.button("Run Chat Assistant"):
        if st.session_state.documents is not None and st.session_state.run_chat_assistant == False:
            
            with st.spinner("ğŸ”„ Running Chat Assistant... Please wait..."):
                db = FAISS.from_documents(st.session_state['documents'], st.session_state["embeddings_model"])
                retriever = db.as_retriever(
                    search_type='mmr',
                    search_kwargs={'k': 4, 'fetch_k': 50, 'lambda_mult': 0.7})
                st.session_state.retriever = retriever
                st.session_state.run_chat_assistant = True

        elif st.session_state.run_chat_assistant == True:
            st.warning("âš ï¸ Please upload a new PDF file first.")        
        else:
            st.warning("âš ï¸ Please upload a PDF first.")

# Display extracted data if available
if st.session_state.df_result is not None:
    st.subheader("ğŸ“Š Extracted Data")
    # Editable DataFrame
    edited_df = st.data_editor(st.session_state.df_result, num_rows="dynamic")
    st.session_state.df_result = edited_df  # Save changes in session state
    st.success("âœ… Changes saved!")
    # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
    csv = edited_df.to_csv(index=False).encode('utf-8')
    st.download_button("ğŸ“¥ Download CSV", csv, "extracted_data.csv", "text/csv")

if st.session_state.run_chat_assistant:
    st.subheader("ğŸ¤– Chat Assistant")
    # ì„¸ì…˜ì— chat historyê°€ ì—†ë‹¤ë©´ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    # ì´ì „ ëŒ€í™” ë‚´ì—­ í‘œì‹œ
    for message in st.session_state["messages"]:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    if prompt := st.chat_input("Enter your question for the Chat Assistant"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state["messages"].append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ëª¨ë¸ì„ í™œìš©í•œ ë‹µë³€ ìƒì„± (ì˜ˆ, parser.rag ì‚¬ìš©)
        with st.chat_message("assistant"):
            # retrieverì™€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì´ìš©í•´ ë‹µë³€ ìƒì„±
            response = parser.rag(st.session_state.retriever, prompt)
            st.markdown(response)
        # ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì‘ë‹µì„ chat historyì— ì¶”ê°€
        st.session_state["messages"].append({"role": "assistant", "content": response})
